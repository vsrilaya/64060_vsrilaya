---
title: "Assignment-3"
author: "Srilaya Valmeekam"
date: "03-05-2022"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r CSV call and variable factoring}
library(caret)
library(dplyr)
library(ggplot2)
library(lattice)
library(knitr)
library(rmarkdown)
library(e1071)
```

```{r}
#importing the Data set
library(readr)
UniversalBank <- read.csv("~/Downloads/UniversalBank.csv")
```

```{r}
##The text that follows simply takes the data file, deletes the zip code and ID (as last time, but unnecessary this time), and factors the relevant variables, first converting the numerical values to qualitative ones.
SLV <- UniversalBank %>% select(Age, Experience, Income, Family, CCAvg, Education, Mortgage,Personal.Loan , Securities.Account,CD.Account , Online, CreditCard)
SLV$CreditCard <- as.factor(SLV$CreditCard)
SLV$Personal.Loan <- as.factor((SLV$Personal.Loan))
SLV$Online <- as.factor(SLV$Online)
```

```{r}
#The train data, validation data, and data division are generated in this way.
selected.var <- c(8,11,12)
set.seed(23)
Train_Index = createDataPartition(SLV$Personal.Loan, p=0.60, list=FALSE)
Train_Data = SLV[Train_Index,selected.var]
Validation_Data = SLV[-Train_Index,selected.var]
```

```{r A}
##A. Create a pivot table for the training data with Online as a column variable, CC as a row variable,and Loan as a secondary row variable. The values inside the table should convey the count. In R use functions melt() and cast(), or function table(). In Python, use panda dataframe methods melt() and pivot().
#Online is a column, and CC and LOAN are both rows in the final pivot table.
attach(Train_Data)
##ftable "function table". 
ftable(CreditCard,Personal.Loan,Online)
detach(Train_Data)
```

##In order to calculate the conditional probability that Loan=1, we add 53 (Loan=1 from ftable) to 497 (Loan=0 from ftable), which makes 550. 53/550 = 0.096363 or 9.64% of the time.

```{r}
##B. Consider the task of classifying a customer who owns a bank credit card and is actively using online banking services. Looking at the pivot table, what is the probability that this customer will accept the loan offer? [This is the probability of loan acceptance (Loan = 1) conditional on having a bank credit card (CC = 1) and being an active user of online banking services (Online = 1)].
prop.table(ftable(Train_Data$CreditCard,Train_Data$Online,Train_Data$Personal.Loan),margin=1)
```

##A percentage pivot table that displays the chance of a loan based on credit card and online data is displayed by the code above.

```{r}
##C. Create two separate pivot tables for the training data. One will have Loan (rows) as a function of Online (columns) and the other will have Loan (rows) as a function of CC.
attach(Train_Data)
ftable(Personal.Loan,Online)
ftable(Personal.Loan,CreditCard)
detach(Train_Data)
```

##In the first column up there, "Internet" makes up a column, "Loans" adds a row, and "Credit Card" makes up a column.

```{r}
##D. Compute the following quantities [P(A | B) means “the probability ofA given B”]:  
prop.table(ftable(Train_Data$Personal.Loan,Train_Data$CreditCard),margin=)
prop.table(ftable(Train_Data$Personal.Loan,Train_Data$Online),margin=1)
```

SLVi) 92/288 = 0.3194 or 31.94%

SLVii) 167/288 = 0.5798 or 57.986%

SLViii) total loans= 1 from table (288) divide by total from table (3000) = 0.096 or 9.6%

SLViV) 812/2712 = 0.2994 or 29.94%

SLVV) 1624/2712 = 0.5988 or 59.88%

SLVVi) total loans=0 from table(2712) divided by total from table (3000) = 0.904 or 90.4%

##E. Use the quantities computed above to compute the naive Bayes probability P(Loan = 1 | CC = 1,Online = 1).

(0.3194 * 0.5798 * 0.096)/[(0.3194 * 0.5798 * 0.096)+(0.2994 * 0.5988 * 0.904)] = 0.0988505642823701 or 9.885%

##F. Compare this value with the one obtained from the pivot table in (B). Which is a more accurate estimate? 

The discrepancy between 0.096363, or 9.64%, and 0.0988505642823701, or 9.885%, is not statistically significant. The pivot table value is the predicted value with greater accuracy because it is independent of the probabilities' independence. E examines the probability of each of those counts, whereas B uses a straightforward calculation from a tally. B is therefore more exact, whereas E is best for generality.

```{r}
##G. Which of the entries in this table are needed for computing P(Loan = 1 | CC = 1, Online = 1)? Run naive Bayes on the data. Examine the model output on training data, and find the entry that corresponds to P(Loan = 1 | CC = 1, Online = 1). Compare this to the number you obtained in (E). 
##training dataset
UniversalBank.SLV <- naiveBayes(Personal.Loan ~ ., data = Train_Data)
UniversalBank.SLV
```
The pivot table in step B can be used to rapidly compute P(LOAN=1|CC=1,Online=1) without relying on the Naive Bayes model, while using the two tables created in step C makes it simple and obvious HOW you are getting P(LOAN=1|CC=1,Online=1)using the Naive Bayes model.

But compared to the probability determined manually in step E, the model's prediction is less possible. The earlier approaches and the Naive Bayes model both forecast probabilities. More probable than the one from step B is the estimated probability. This might be the case because step E requires manual computation, which carries the risk of error when rounding fractions and only yields an approximation.

```{r}
## SLV confusion matrix about Train_Data
##Training
predicting.class <- predict(UniversalBank.SLV, newdata = Train_Data)
confusionMatrix(predicting.class, Train_Data$Personal.Loan)
```

This model had a low degree of specificity despite its high sensitivity. Despite the fact that the reference data held all actual values, the model predicted that all values would be 0. Even if the model totally missed all values of 1, it would still produce a 90.4% accuracy because of the sizeable amount of 0.

```{r Validation set}
predicting.prob <- predict(UniversalBank.SLV, newdata=Validation_Data, type="raw")
predicting.class <- predict(UniversalBank.SLV, newdata = Validation_Data)
confusionMatrix(predicting.class, Validation_Data$Personal.Loan)
```

Let's now examine the model visually and select the optimal threshold.
```{r ROC}
library(pROC)
roc(Validation_Data$Personal.Loan,predicting.prob[,1])
plot.roc(Validation_Data$Personal.Loan,predicting.prob[,1],print.thres="best")
```

Therefore, it can be shown that the model is enhanced by selecting a limit of 0.906, which would reduce sensitivity to 0.495 and raise specificity to 0.576.